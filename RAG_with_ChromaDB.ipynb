{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG with Chroma and GPT3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings,OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 13 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(file_path='Data/RAG_Documents/document.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "chunk_size = 200\n",
    "chunk_overlap = 50\n",
    "rc_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = rc_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding the data and saving to a vector db\n",
    "from langchain_openai import OpenAIEmbeddings,OpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "chromadb = Chroma(persist_directory='Data/Chroma/',embedding_function=embedding_function)\n",
    "chromadb.persist()\n",
    "docstorage = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data'])\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "db = docstorage\n",
    "print(db.get().keys())\n",
    "print(len(db.get()[\"ids\"]))\n",
    "\n",
    "#db.get()['documents']\n",
    "# # Print the list of source files\n",
    "# for x in range(len(db.get()[\"ids\"])):\n",
    "#     # print(db.get()[\"metadatas\"][x])\n",
    "#     doc = db.get()[\"metadatas\"][x]\n",
    "#     source = doc[\"source\"]\n",
    "#     print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#querying the db\n",
    "query = 'what is the primary architecture presented in the document?'\n",
    "result = chromadb.similarity_search_with_relevance_scores(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is the primary architecture presented in the document?', 'result': '\\nThe primary architecture presented in the document is a visual representation of how things are connected, with AI on top and other components branching out. It is generated using Microsoft Designer.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = docstorage.as_retriever()\n",
    "qa = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "\n",
    "query='what is the primary architecture presented in the document?'\n",
    "results = qa.invoke(query)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': ' The primary architecture presented in the document is a comparison between human and machine cognition, with AI at the top and other components branching out. The document also includes a visual representation of how things are connected, and was generated using Microsoft Designer.\\n', 'sources': 'Data/RAG_Documents/document.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#Showing reference to the document in the response\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_source = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "results = qa_source.invoke(query,return_only_outputs=True)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
