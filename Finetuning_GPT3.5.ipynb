{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll fine tune OpenAI's GPT3.5 turbo model based on our own dataset\n",
    "\n",
    "## Data\n",
    "This case study uses the Yahoo Non-Factoid Question Dataset derived from the Yahoo’s Webscope L6 collection\n",
    "- It has 87,361 questions and their corresponding answers.  \n",
    "- Freely available from [Hugging Face](https://huggingface.co/datasets/yahoo_answers_qa).  \n",
    "\n",
    "## Main tasks\n",
    "The main tasks include  \n",
    "- Loading data from Hugging Face  \n",
    "- Preprocess the data for fine-tuning  \n",
    "- Fine-tune the GPT3.5 model  \n",
    "- Interaction with the fine-tuned model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import FineTuningJob, ChatCompletion\n",
    "from datasets import load_dataset \n",
    "from time import sleep\n",
    "import random \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll load the dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_answers_qa = load_dataset('yahoo_answers_qa', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
       "    num_rows: 87362\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_answers_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a subset of out data for fine-tuning to minimize costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 150\n",
    "yahoo_answers_qa = yahoo_answers_qa.select(range(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_answers_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning, the data needs to be in the following format for each pair of questions and answers across the entire training and validation data.\n",
    "\n",
    "Each observation from the data is considered to be a message with three main roles, and each role has a content: \n",
    "\n",
    "- The first `role` is the `system` and the `content` is the description of what the system should do  \n",
    "- The second `role` is the `user`, and the `content` is the question from the user  \n",
    "- The third `role` is the `assistant` and the `content` is the answer to the user's question    \n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"SYSTEM's ROLE\"},\n",
    "        {\"role\": \"user\", \"content\": \"USER's QUESTION\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"SYSTEM's RESPONSE\"}\n",
    "    ] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a helper function to format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "     formatted_data = [{\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer users' question with a polite tone\"},\n",
    "                {\"role\": \"user\", \"content\": message[\"question\"]},\n",
    "                {\"role\": \"assistant\", \"content\": message[\"answer\"]}\n",
    "            ] \n",
    "        } for message in data \n",
    "    ]\n",
    "     random.shuffle(formatted_data)\n",
    "     return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': \"You are a helpful assistant. Answer users' question with a polite tone\"},\n",
       "  {'role': 'user',\n",
       "   'content': \"Why can't I get used to console-style controls in FPS games?\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I suggest going back to your computer for FPS. Console controls are not well-suited to FPS style gameplay. The only console that will truly be able to pull this off well is the Nintendo Revolution (which will come out next year).'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data = format_data(yahoo_answers_qa)\n",
    "formatted_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the data into training and validation datasets and save them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size is 105 and validation data size is 45\n"
     ]
    }
   ],
   "source": [
    "train_size=int(0.7 * len(formatted_data))\n",
    "\n",
    "training_data = formatted_data[:train_size]\n",
    "validation_data = formatted_data[train_size:]\n",
    "\n",
    "print(f\"training data size is {len(training_data)} and validation data size is {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(dict_data,file_name):\n",
    "    with open(file_name,'w') as outfile:\n",
    "        for item in dict_data:\n",
    "            json.dump(item,outfile)\n",
    "            outfile.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(training_data,'Data/training_data.jsonl') # max limit of json is 2GB, so using jsonl will remove that limit\n",
    "save_data(validation_data,'Data/validation_data.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to OpenAI, save the training and validation data ids in a variable as we'll need them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai_api_key=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_finetuning_data(data_path):\n",
    "    client=openai.OpenAI(api_key=openai_api_key)\n",
    "    uploaded_file = client.files.create(file=open(data_path,mode='rb'),\n",
    "                                       purpose='fine-tune'\n",
    "                                       )\n",
    "    return uploaded_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_finetuning_data = upload_finetuning_data('Data/training_data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-iF0ylhVb8AQsZEg5zz1lb02E', bytes=53636, created_at=1713833141, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "print(uploaded_finetuning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-iF0ylhVb8AQsZEg5zz1lb02E\n"
     ]
    }
   ],
   "source": [
    "uploaded_training_id = uploaded_finetuning_data.id\n",
    "print(uploaded_training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-ojPCIBYogTXAtwVZwEK5Tnds\n"
     ]
    }
   ],
   "source": [
    "uploaded_validation_data = upload_finetuning_data('Data/validation_data.jsonl')\n",
    "uploaded_validation_id = uploaded_validation_data.id\n",
    "print(uploaded_validation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to fine tune the data\n",
    "\n",
    "def create_fine_tuning(base_model, train_id, val_id):\n",
    "    client=openai.OpenAI(api_key=openai_api_key)\n",
    "    fine_tuning_response = client.fine_tuning.jobs.create(\n",
    "        training_file = train_id,\n",
    "        validation_file = val_id,\n",
    "        model = base_model\n",
    "    )\n",
    "    \n",
    "    return fine_tuning_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "fine_tuning_response = create_fine_tuning(base_model, \n",
    "                                         uploaded_training_id, \n",
    "                                         uploaded_validation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-XuiCNXwwP0ObfirV9yPWRzYc', created_at=1713833160, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-x7gmHBS9mvLkn1vPNWa1EIi7', result_files=[], seed=769438601, status='validating_files', trained_tokens=None, training_file='file-iF0ylhVb8AQsZEg5zz1lb02E', validation_file='file-ojPCIBYogTXAtwVZwEK5Tnds', integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_job_id = fine_tuning_response.id\n",
    "fine_tuning_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine_tuned_model parameter in the response is null, that means that the fine tuning is not complete. We'll create a loop and wait\n",
    "for fine tuning to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning in progress...\n",
      "Fine-tuning in progress...\n",
      "Fine-tuning in progress...\n",
      "Fine-tuning in progress...\n",
      "Fine-tuning in progress...\n",
      "Fine-tuning completed!\n",
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:personal::9Gynxg6K\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    client=openai.OpenAI(api_key=openai_api_key)\n",
    "    fine_tuning_response = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "    fine_tuned_model_ID = fine_tuning_response.fine_tuned_model\n",
    "    \n",
    "    if(fine_tuned_model_ID != None):\n",
    "        print(\"Fine-tuning completed!\")\n",
    "        print(f\"Fine-tuned model ID: {fine_tuned_model_ID}\")\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        print(\"Fine-tuning in progress...\")\n",
    "        sleep(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, model_ID):\n",
    "  client=openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "  message = [\n",
    "              {\n",
    "                  \"role\": \"system\",\n",
    "                  \"content\": \"You are the Yahoo platform user's assistant. Please reply users' answer using polite and respectful language.spectful language.\"\n",
    "              },\n",
    "\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": question\n",
    "              }\n",
    "            ]\n",
    "\n",
    "  # Start inferencing\n",
    "  model_completion = client.chat.completions.create(model=model_ID, \n",
    "                                          messages = message)\n",
    "\n",
    "  # Get the response\n",
    "  response = model_completion.choices[0].message\n",
    "\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model response: \n",
      "online trading is a good idea for a test run but personally i would go to a stock broker that offers free investemtn consultatrions, citi bank is one bank i know that you can do so, Bear Sterns is another ....委.._SY。..。registered credit cards work well too and suddenly stocks are sort of gambling but you can actually deduct up tp $3000 of loses..but that is really another type of account where you deposit money and they control the type of stocks you can invest in.. happy investing.. (ps and your money is your own)\n"
     ]
    }
   ],
   "source": [
    "question = \"How to invest in stocks?\"\n",
    "response_fine_tuned_model = answer_question(question, fine_tuned_model_ID)\n",
    "print(f\"Fine-tuned model response: \\n{response_fine_tuned_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model response: \n",
      "Investing in stocks can be a great way to grow your wealth, but it's important to do thorough research and understand the risks involved. Here are some steps you can take to start investing in stocks:\n",
      "\n",
      "1. Educate yourself: Take the time to learn about the stock market, different investment strategies, and how to analyze companies.\n",
      "\n",
      "2. Set financial goals: Determine your investment goals, risk tolerance, and timeframe for investing.\n",
      "\n",
      "3. Choose a brokerage account: Open an account with a reputable brokerage firm that offers trading services.\n",
      "\n",
      "4. Build a diversified portfolio: Consider investing in a mix of stocks from different sectors to spread out your risk.\n",
      "\n",
      "5. Start small: Begin by investing a small amount of money until you gain more experience and confidence in your investment decisions.\n",
      "\n",
      "6. Monitor your investments: Regularly review your portfolio and make adjustments as needed based on market conditions and your financial goals.\n",
      "\n",
      "Remember, investing in stocks carries risks, so it's important to be prepared for potential losses. Consider consulting with a financial advisor for personalized investment advice.\n"
     ]
    }
   ],
   "source": [
    "response_base_model = answer_question(question, 'gpt-3.5-turbo')\n",
    "\n",
    "print(f\"Base model response: \\n{response_base_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
